\section*{Preliminaries and notation}
\begin{itemize}
    \item $S \subseteq \zo^*$ defines set $S$ as a finite subset of $\zo$ all finite-length strings. 
    \item $x \in_R S$, $R$ indicates x is chosen randomly / uniformly from $S$
    \item $U_n$ x is chosen from the set of all n-bit strings
    \item $\mu(\cdot)$ means the negligible function can take any input. Negligible functions decrease faster than inverse polynomial as $n$ increases
    \item must use positive polynomial, if not, maybe it won't be negligible. We want $\mu(n) < \frac{1}{p(n)}$
    \item $\lambda$ is an empty string
\end{itemize}

\subsubsection*{Polynomial time, Security parameter}
\begin{itemize}
    \item Polynomial time refers to the computational complexity of an algorithm with respect to the security parameter
    \item it means the protocol is efficient and practical because algorithms are feasible in polynomial time
    \item But also secure because breaking the algorithm is infeasible
    \item security parameter determines level of security e.g. length of keys in bits
    \item an algorithm running in polynomial time in the security parameter can be expressed as a polynomial function of the security parameter. That is, there exists $ p(\lambda)$ such that $\mathcal{O}(p(\lambda))$
    \item E.g. if $\lambda$ = 128 bits runs in polynomial time, running time will be a function of $\lambda$ like $\mathcal{O}\lambda^2$
    \item In contrast to exponential time which are $\mathcal{O}2^{\lambda}$
\end{itemize}

\subsection*{Theory of Computation}
\begin{itemize}
    \item a turing machine is a theoretical device that "manipulates symbols on a strip of tape according to a table of rules" simulating algorithm logic
    \item Includes an infinitely long tape divided into blocks, a head can read and write symbols on the tape, a state register storing the machine state, a finite table of instructions
    \item We use unary $1^n$, a string of 1's on the security paramter tape for reasons:
    \begin{itemize}
        \item Unary: $1^n$ provides unary representation of $n$ meaning input length corresponds with $n$, the longest possible representation (Worst case and Lower bound)
        \item in binary, $n$ is represented in $log_2(n)$ bits. e.g. 1000 is 11111101000 = 10 bits long. In unary, $1^{1000}$ is a string of 1000 ones.
        \item using binary, an algorithm taking time proportional to input length would run in $\mathcal{O}(log(n))$ which runs in $\mathcal{O}(n)$
    \end{itemize}
    \item Security parameter tape is used to model how a system scales with security parameter, $1^{\lambda}$ is written on it e.g. string of 1's
    \item This means, the function is bounded by the length of the input on the security parameter tape
    \item Advice Tape: is used in non-uniform computation, it's additional information given to an algorithm 
\end{itemize}


\subsubsection*{Uniform, Non-Uniform}
Non uniform algorithms aren't non-uniform randomness! 
Uniform algorithms don't change procedure based on the input size. Non-uniform algorithms can have logic based around the input size.
Uniform algorithms have a fixed strategy, non-uniform can adapt. 
The non-uniformity is not about randomness but the potential for the algorithm to have different strategies for input lengths.
Allowing a distinguisher algorithm $D$ to be non-uniform means it's a powerful attacker that has different strategies for each input length (key length or message size) and can more easily distinguish.

\subsubsection*{Negligible Function}
A function $\mu(n)$ is negligible if it decreases faster than the inverse of any polynomial.
\begin{definition}
    given a function $\mu : \Nat \to [0,1]$, we say $\mu$ is negligible if for all polynomials $p$, there exists $n_0 \in \Nat$ such that 
$$
    \forall \; n \geq n_0,\;   \; \mu(n) \leq \frac{1}{p(n)}
$$
\end{definition}
Tests: are the following negligible?
\begin{enumerate}
    \item $\mu(n) = \frac{1}{n^2}$
    \item $\mu(n) = \qquad \frac{1}{2^n}$ 
    \item $\mu(n) = \frac{1}{n!}$ 
    \item $\mu(n) = \qquad \frac{1}{2^{-n}}$ 
    \item $\mu(n) = \frac{1}{2^{\log(n)}}$ 
    \item $\mu(n) = \qquad \frac{1}{n^{\log(n)}}$ 
\end{enumerate}

Answer and Discussion
\begin{enumerate}
    \item $\frac{1}{n^k}$ is a inverse power function, aka polynomial time decreasing function. e.g. inverse cubic $1/n^3$, inverse quartic $1/n^4$, they approach 0 as $n$ approaches $\infty$. They are efficiently computable and tractable, though non-negligible. \\
    \item $\mu(n) = \frac{1}{2^n}$ is an inverse exponential function and will always satsify the inequality because an exponential function will decrease faster than the inverse polynomial.  It's non-negligible and used in crypto\\
    \item $\mu(n) = \frac{1}{n!}$ is an inverse factorial, defined only for non-negative, it's super exponential decreasing faster than exponential and isn't seen in computer science but maybe in poisson distribution. It's non-negligible but not used \\
    \item $\mu(n) = \frac{1}{2^{-n}}$ without calculation, this is $2^n$ which is exponential growth rather than decay, definately not negligible. \\
    \item $\frac{1}{2^{\log(n)}}$ is negligible but is sub-exponential, decreasing slower than $\frac{1}{2^n}$. For any $p(n)$ we show that a large enough $n$ satisifes our inequality. $\frac{1}{2^{\log(n)}} = \frac{1}{n^{\log(2)}}$, $n^{\log(2)}$ = $n^{0.693}$ therefore for sufficiently large n, this satifies the inequality. \\
    \item $\frac{1}{n^{\log(n)}}$ decreases faster than the above
\end{enumerate}
log/exp rule: $x^{\log_a^{(y)}} = y^{\log_a^{(x)}}$





\subsubsection*{Distinguishing Advantage}
Quantifies $D$'s ability to distinguish between $X$ and $Y$ when given a sample from each $\Pr\[D(X(a,n)) = 1 \] - \Pr\[D(Y(a,n))=1\]$.
The definition states this distinguishing advantage must be $\leq$ some negligible function $\mu(n)$ for suffiently large $n$. 

\subsubsection*{Algorithm bounds}
The definition of computational indistinguishability states the distinguishing advantage $\Pr\[D(X(a,n)) = 1 \] - \Pr\[D(Y(a,n))=1\]$ is bound by a negligible function which by definition 
"Given unbounded computational power"
"Brute force atttack"

\section*{Computational Indistinguishability}
Two probability ensembles, $X, Y$ are computationally indistinguishabile: $X \stackrel{c}{\equiv} Y$ if
$$
\abs{
    \Pr\[D(X(a,n)) = 1 \] - \Pr\[D(Y(a,n))=1\]
} \leq \mu(n)
$$

\begin{itemize}
    \item $n$ is input length, the security parameter
    \item $a$ a binary string of any length, could be public parameters
    \item ensembles $X, Y$ are computationally indistinguishable if no polynomial time algorithm $D$ can tell them apart with greater than negligible advantage.
    \item $D$ is a $\ppt$ algorithm trying to distinguish between samples from $X$ and $Y$, not guessing the bit
    \item $D's$ output is binary $\zo$. Output 1 means a successful distinguish
    \item We look at the absolute value difference in probability of $D$ outputting 1 for $X$ vs $Y$
\end{itemize}

$$
X = \{X(a,n)\}_{a\in\zo^*; n \in \mathbb{N}}
$$

\begin{itemize}
    \item Set $X = \{X(a,n)\}$ defines the set of random variables $X$
    \item Subscript ${a\in\zo^*; n \in \mathbb{N}}$ defines the indexing, that is, exactly what values of $a, n$ can take for infinitely any element in set $X$. e.g. $X('01', 3)$ is the index of a random variable $X$ where $a$ is a binary string of any finite length "0, 1, 01, 000", $n$ is a natural number 1,2
    \item $\zo^*$ is the Kleene star operation, means all finite strings, an infinite set because there's no limit to the length
    \item $n\in\Nat$ means $n$ can be any natural number, also an infinite set
    \item indexing gives us an address or a way to talk about 1 specific random variable rather than the collection
    \item "probability ensemble" is a term in cryptography / probability theory referring to a collection or family of probability distributions or random variables. Used to describe systems where behaviours depend on on input length, security parameter, etc
    \item "ensemble" means we're dealing with a collection of probabilistic objects rather than a single fixed distribution
\end{itemize}


\subsubsection*{Non-uniformity}
\begin{itemize}
    \item $D$ is defined above as non-uniform which increases its power to distinguish
    \item basically says the concept of computational indistinguishability is non-uniform. Even if we start with uniform ensembles of $X, Y$, the distinguisher that potentially breaks indistinguishability might be non-uniform
    \item Non-uniformity comes from the fact that for different input length $n$, there may be different aux input $a$ that allows a distinguisher to win
    \item The value $a$ is a public parameter that needs to be "written on the advice tape of the reduction algorithm
    \item This means securtity proofs and analysis need to consider non-uniform adversaries 
\end{itemize}

\subsubsection*{Order of quantifiers for computational indistinguishability}
\begin{itemize}
    \item the main distinction this section is making is allowing $\mu$ the negligible function to depend on $a$, as in $\mu_a$ or $\mu(a,n)$ is very different to $\mu(\cdot)$ the prior definition of a neligible function. 
    \item a negligible function that's parameterized by $a$ leads to a weaker security definition for computational complexity. 
    \item The negligible probability of distinguishing doesn't vary on the specific problem instance $a$, only on the security parameter $n$.
    \item a quantifier specifies the number of elements in a domain satisfy a given predicate. E.g. for all $\forall$, there exists $\exists$. This section identifies the fact that ordering changes the meaning of a statement.
    \item "For all $a$, there exists a negligible function" is different to saying "there exists a negligible function for all $a$". The former says that every $a$ uses the same negligible function, the latter says that all $a$ have a negligible function but it could use different.
    \item $X \stackrel{c}{\equiv} Y$ if for every non-uniform ppt algo $D$, there exists a negl. funcion $\mu(\cdot)$ for every $a\in\zo^*$ and every $n \in \mathbb{N}$ such that
    $$
    \{X(a,n)\}_{a\in\zo^*; n \in \mathbb{N}}  \stackrel{c}{\equiv} \{Y(a,n)\}_{a\in\zo^*; n \in \mathbb{N}}
    $$
    Is not the same as: for every $a\in\zo^*$ it holds that 
    $$
    \{X(a,n)\}_{n \in \mathbb{N}}  \stackrel{c}{\equiv} \{Y(a,n)\}_{n \in \mathbb{N}}
    $$
    \item For the piecewise function below, $|a|$ denotes the length of a bit string $a$. 
    $$
    \mu_a(n)=
    \begin{cases}
        1, & \text{if } n < 2^{|a|} \\
        2^{-n}, & \text{if } n \geq 2^{|a|}
    \end{cases}
    $$\\
    If the security parameter $n$ is less than the length of the bit string $a$ then the negligible function is not negligible. \\
    If the security parameter $n$ is more than the length of the bit string $a$, the negligible function is exponential in $n$ and thus negligible.
    \item $a$ can be the parameters of a crypto scheme, a public key, other instance specific information. Security should not rely on an instance of a problem, rather the security parameter.
\end{itemize}

\subsubsection*{Semantic Security}
\begin{itemize}
    \item polynomial length plain texts = plaintext length is bounded by a polynomial function of the security parameter. Notice the maximum length of the plaintext depends on a polynomial function of the security parameter $\text{secparam}^3$ rather than $\text{secparam}^n$ \\
    \lstset{language=Python, basicstyle=\ttfamily, frame=single}
    \begin{lstlisting}
    fn A(plaintext, secparam):
        max_len = secparam^3
        if len(plaintext) > max_len:
            return plaintext[:max_len] //or return error
        else:
            return plaintext
    \end{lstlisting}
    \item Arbitrary distributions of plaintext: refers to any distribution of plaintexts, e.g. uniformly random such as encrypting output of a hash function or uuid, non-uniform such as encrypting names, ages, or email addresses where distribution is clustered around ranges or common names, or fixed distribution such as encryption of "YES" or "NO" type responses.
    \item Aim of the adversary is to learn some function $f$ of the plaintext: \\
    We model this scenario 
    \lstset{language=Python, basicstyle=\ttfamily, frame=single}
    \begin{lstlisting}
    fn adversary_guess(ciphertext, auxillary_info, f):
        
        % advesary strategy to guess f(plaintext)
        guess = secret_strategy(ciphertext, auxillary_info)
        return guess
    
    fn evaluate_security(plaintext, ciphertext, auxillary_info, f):
        actual_value = f(plain_text)
        guess = adversary_guess(ciphertext, auxillary_info, f)
        return guess == actual_value
    \end{lstlisting}
    The adversaries wins if their function $f$ learns anything about the ciphertext, such as the first bit, if a number is even or odd, the length of a string.
    \item Auxillary Information: denoted as $h$ is additional information available to the adversary, like partial information of the ciphertext e.g. the language of the plaintext, or side-channel information.
\end{itemize}
